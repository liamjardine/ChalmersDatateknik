{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ZYIWUuEETWv"
   },
   "source": [
    "# Q-learning with FrozenLake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FiK2QFfTETWy"
   },
   "source": [
    "Based on https://github.com/ioarun/openai-gym/blob/master/frozenlake/frozenlake-qlearning.py \n",
    "\n",
    "Environment: https://www.gymlibrary.dev/environments/toy_text/frozen_lake/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "g1xepI8xETW0"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nvM8XQq2hKO8"
   },
   "source": [
    "First we need to install pygame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "oaB8U52EKmsM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pygame\n",
      "  Downloading pygame-2.1.2-cp39-cp39-win_amd64.whl (8.4 MB)\n",
      "Installing collected packages: pygame\n",
      "Successfully installed pygame-2.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uF92FCzZMWPn"
   },
   "outputs": [],
   "source": [
    "!pip install gym pyvirtualdisplay > /dev/null 2>&1\n",
    "!apt-get install -y xvfb python-opengl ffmpeg > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hS7L8kFMLkjN"
   },
   "source": [
    "Next, we install the needed requirements to display an Atari game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "78BfQoQKOq7z"
   },
   "outputs": [],
   "source": [
    "!apt-get update > /dev/null 2>&1\n",
    "!apt-get install cmake > /dev/null 2>&1\n",
    "!pip install --upgrade setuptools 2>&1\n",
    "!pip install ez_setup > /dev/null 2>&1\n",
    "!pip install gym[atari] > /dev/null 2>&1\n",
    "!pip install pyglet==1.2.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NjTHm2SpLz10"
   },
   "source": [
    "Next, we define the functions used to show the video by adding it to the CoLab notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "T9RpF49oOsZj"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyvirtualdisplay'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mbase64\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTML\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyvirtualdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Display\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m display \u001b[38;5;28;01mas\u001b[39;00m ipythondisplay\n\u001b[0;32m     10\u001b[0m display \u001b[38;5;241m=\u001b[39m Display(visible\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1400\u001b[39m, \u001b[38;5;241m900\u001b[39m))\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pyvirtualdisplay'"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "from gym.wrappers import RecordVideo \n",
    "import glob\n",
    "import io\n",
    "import base64\n",
    "from IPython.display import HTML\n",
    "from pyvirtualdisplay import Display\n",
    "from IPython import display as ipythondisplay\n",
    "\n",
    "display = Display(visible=0, size=(1400, 900))\n",
    "display.start()\n",
    "\n",
    "\"\"\"\n",
    "Utility functions to enable video recording of gym environment \n",
    "and displaying it.\n",
    "To enable video, just do \"env = wrap_env(env)\"\"\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def show_video():\n",
    "    mp4list = glob.glob('video/*.mp4')\n",
    "    if len(mp4list) > 0:\n",
    "        mp4 = mp4list[0]\n",
    "        video = io.open(mp4, 'r+b').read()\n",
    "        encoded = base64.b64encode(video)\n",
    "        ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n",
    "                loop controls style=\"height: 400px;\">\n",
    "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
    "             </video>'''.format(encoded.decode('ascii'))))\n",
    "    else:\n",
    "        print(\"Could not find video\")\n",
    "\n",
    "\n",
    "def wrap_env(env):\n",
    "    env = RecordVideo(env, './video')\n",
    "    return env\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9MHw88AoETW2"
   },
   "source": [
    "## Problem description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PxrVYuTZETW3"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "The agent controls the movement of a character in a grid world. Some tiles of the grid are walkable, and others lead to the agent falling into the water. Additionally, the movement direction of the agent is uncertain and only partially depends on the chosen direction. The agent is rewarded for finding a walkable path to a goal tile.\n",
    "\n",
    "A frozenlake-v0 is a 4x4 grid world that looks as follows:\n",
    "SFFF       \n",
    "FHFH       \n",
    "FFFH       \n",
    "HFFG       \n",
    "\n",
    "Meaning of the letters:\n",
    "S: starting point, safe\n",
    "F: frozen surface, safe\n",
    "H: hole, fall to your doom\n",
    "G: goal, where the frisbee is located\n",
    "\n",
    "The 16 states (position of the agent): \n",
    "State 0: upper left corner (Start)\n",
    "...\n",
    "State 15: Lower right corner (Goal)\n",
    "\n",
    "The 4 actions (moves of the agent):\n",
    "LEFT = 0,\n",
    "DOWN = 1,\n",
    "RIGHT = 2,\n",
    "UP = 3.\n",
    "\n",
    "Reward:\n",
    "The episode ends when you reach the goal or fall into the water. \n",
    "You receive a reward of 1 if you reach the goal, and 0 otherwise.\n",
    "\n",
    "Effect of actions:\n",
    "        def inc(row, col, a):\n",
    "            if a == LEFT:\n",
    "                col = max(col-1,0)\n",
    "            elif a == DOWN:\n",
    "                row = min(row+1,nrow-1)\n",
    "            elif a == RIGHT:\n",
    "                col = min(col+1,ncol-1)\n",
    "            elif a == UP:\n",
    "                row = max(row-1,0)\n",
    "            return (row, col)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m9TEiEeUETW4"
   },
   "source": [
    "## Define environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "EPsmtmq7ETW5"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wrap_env' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m env \u001b[38;5;241m=\u001b[39m \u001b[43mwrap_env\u001b[49m(gym\u001b[38;5;241m.\u001b[39mmake(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFrozenLake-v1\u001b[39m\u001b[38;5;124m\"\u001b[39m,is_slippery\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,new_step_api\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,render_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrgb_array\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'wrap_env' is not defined"
     ]
    }
   ],
   "source": [
    "env = wrap_env(gym.make(\"FrozenLake-v1\",is_slippery=False,new_step_api=True,render_mode=\"rgb_array\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "xgNTmQ2XETW6"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'env' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43menv\u001b[49m\u001b[38;5;241m.\u001b[39mreset()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'env' is not defined"
     ]
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "tZmC7SFBFPLF"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'env' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43menv\u001b[49m\u001b[38;5;241m.\u001b[39mrender()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'env' is not defined"
     ]
    }
   ],
   "source": [
    "env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "52fKq2w22_B8"
   },
   "source": [
    "If you don't see the \"video\", click on the Folder icon in the left bar in Colab, click 'video', download the mp4-file and run. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "85-oR8thETW7"
   },
   "source": [
    "## Actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zHnIZoYcETW8"
   },
   "outputs": [],
   "source": [
    "#Sample actions for exploration:\n",
    "env.action_space.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jKYt926bETW8"
   },
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4QNLEY1BjQ_e"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "2HuRQxV9ETW9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_episodes = 15000 #20000 #60000\n",
    "gamma = 0.95 #0.99\n",
    "learning_rate = 0.7 #0.95 #0.85\n",
    "epsilon = 0.5#1 #0.15 #0.1\n",
    "\n",
    "# initialize the Q table\n",
    "Q = np.zeros([16, 4])\n",
    "Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-eaoj-WBETW-"
   },
   "source": [
    "## Training the Q-table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "kFmfTxX4ETW_"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'env' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_episodes):\n\u001b[1;32m----> 2\u001b[0m \tstate \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241m.\u001b[39mreset()\n\u001b[0;32m      3\u001b[0m \tdone \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \t\u001b[38;5;28;01mwhile\u001b[39;00m done \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m      5\u001b[0m         \u001b[38;5;66;03m# First we select an action:\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'env' is not defined"
     ]
    }
   ],
   "source": [
    "for _ in range(num_episodes):\n",
    "\tstate = env.reset()\n",
    "\tdone = False\n",
    "\twhile done == False:\n",
    "        # First we select an action:\n",
    "\t\tif random.uniform(0, 1) < epsilon: # Flip a skewed coin\n",
    "\t\t\taction = env.action_space.sample() # Explore action space\n",
    "\t\telse:\n",
    "\t\t\taction = np.argmax(Q[state,:]) # Exploit learned values\n",
    "        # Then we perform the action and receive the feedback from the environment\n",
    "\t\tnew_state, reward, done, info = env.step(action)\n",
    "        # Finally we learn from the experience by updating the Q-value of the selected action\n",
    "\t\tupdate = reward + (gamma*np.max(Q[new_state,:])) - Q[state, action]\n",
    "\t\tQ[state,action] += learning_rate*update \n",
    "\t\tstate = new_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ATi77JSgETW_"
   },
   "outputs": [],
   "source": [
    "Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "THSM5KnEETXA"
   },
   "source": [
    "## Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "Al9ig0v8ETXA",
    "outputId": "6587179f-81e7-4629-8854-00a0a0fcaf71"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'\\nLet us sanity check some of the Q-values. \\nFirst we recall what the environment looks like:\\nSFFF       \\nFHFH       \\nFFFH       \\nHFFG       \\n\\nAnd what the 4 actions are:\\nLEFT = 0\\nDOWN = 1\\nRIGHT = 2\\nUP = 3\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Let us sanity check some of the Q-values. \n",
    "First we recall what the environment looks like:\n",
    "SFFF       \n",
    "FHFH       \n",
    "FFFH       \n",
    "HFFG       \n",
    "\n",
    "And what the 4 actions are:\n",
    "LEFT = 0\n",
    "DOWN = 1\n",
    "RIGHT = 2\n",
    "UP = 3\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nExyEH_4ETXA"
   },
   "outputs": [],
   "source": [
    "np.argmax(Q[0])\n",
    "#Should be 1 or 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yXzW87iyETXB"
   },
   "outputs": [],
   "source": [
    "np.argmax(Q[3])\n",
    "#Should be 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IRBeoSWGETXB"
   },
   "outputs": [],
   "source": [
    "np.argmax(Q[10])\n",
    "#Should be 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MAdjrNnsETXC"
   },
   "outputs": [],
   "source": [
    "np.argmax(Q[14])\n",
    "#Should be 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lWPkPke6ETXC"
   },
   "source": [
    "## Using the Q-table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7HMQpAS4ETXC"
   },
   "outputs": [],
   "source": [
    "# Is our Q good enough to guide us from start to goal without falling into the water?\n",
    "env = wrap_env(gym.make(\"FrozenLake-v1\",is_slippery=False))\n",
    "state = env.reset()\n",
    "\n",
    "for step in range(10):\n",
    "    env.render()\n",
    "    # Take the action (index) with the maximum expected discounted future reward given that state\n",
    "    #action = env.action_space.sample()\n",
    "    action = np.argmax(Q[state,:])\n",
    "    print(\"Step \",step,\": Action \",action)\n",
    "    state, reward, done, info = env.step(action)\n",
    "\n",
    "    if done:\n",
    "        break\n",
    "\n",
    "#env.close()\n",
    "show_video()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v4Z3kqeghkyH"
   },
   "source": [
    "Note: If old videos are in the video catalogue, then the first video will always be shown. By removing all videos from there you will be sure that the latest Frozen Lake video will be shown.  "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
